{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fB4TiOyU2aPk"
      },
      "source": [
        "# 一个升级后的批量翻译代码\n",
        "\n",
        "这个代码最初由黄泓森进行开发，由李鲁鲁转到colab并进行了更改\n",
        "\n",
        "[骆驼项目主页](https://github.com/LC1332/Luotuo-Chinese-LLM)\n",
        "\n",
        "如果你使用我们的代码获取了有用的数据，也欢迎分享给我们，或者告诉我们你公开后的github/huggingface链接\n",
        "\n",
        "如果你使用我们的代码获取数据并发表了论文或者tech report，欢迎cite我们的github repo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YzEAdry5GRz4"
      },
      "source": [
        "## 安装环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY9B-984F_mQ",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install aiofiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7Ddf_CbGBCE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import openai\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import aiofiles\n",
        "from functools import partial\n",
        "from tqdm.asyncio import tqdm as tqdm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v0rXCoAWGT0d"
      },
      "source": [
        "## 输入你的openAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWfEZjVbGnon"
      },
      "outputs": [],
      "source": [
        "# 在这里输入你的openAI API token\n",
        "\n",
        "api_key = [\"sk-\"]\n",
        "\n",
        "\n",
        "class KeyPool:\n",
        "    def __init__(self, strings):\n",
        "        self.pool = list(strings)\n",
        "        self.last_used = {s: -1 for s in strings}\n",
        "\n",
        "    def getKey(self):\n",
        "        result = min(self.last_used, key=self.last_used.get)\n",
        "        self.last_used[result] = int(time.time() * 1000)\n",
        "        return result\n",
        "\n",
        "pool = KeyPool(api_key)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hGsk442ZHJcs"
      },
      "source": [
        "## 指定工作目录\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1A5kyTFHpjC"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo43M636J3KT"
      },
      "source": [
        "## 获取需要翻译的样本\n",
        "\n",
        "这里我们使用WizardLM的样本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTYu1i1_Jyxw"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/WizardLM/main/data/WizardLM_testset.jsonl -O WizardLM_testset.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39UbhftwKDGH"
      },
      "outputs": [],
      "source": [
        "delay = 0.05\n",
        "\n",
        "concurrency_limit = 64\n",
        "\n",
        "input_file = \"WizardLM_testset.jsonl\"\n",
        "\n",
        "# 数据缓存目录\n",
        "temp_path = \"/content/temp\"\n",
        "\n",
        "# 数据输出目录\n",
        "output_path = \"/content/translate\"\n",
        "\n",
        "output_prefix = \"WizardLM_tr\"\n",
        "\n",
        "max_file_size = 1024**3\n",
        "\n",
        "# 需要翻译的字段\n",
        "entries = [\"Instruction\"]\n",
        "\n",
        "os.system(f\"mkdir -p {temp_path} {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7a7AdXAF_mR",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "async def getTranslation(item, entries: list = []):\n",
        "    async def get(text):\n",
        "        text = text.replace(\"\\n\", \" \")\n",
        "        openai.api_key = pool.getKey()\n",
        "        try:\n",
        "            resp = await openai.ChatCompletion.acreate(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"这是一个能够将文本翻译成中文的AI助手。请将引号中的文本翻译成简体中文。\",\n",
        "                    },\n",
        "                    {\"role\": \"user\", \"content\": f'\"\"\"\\n{text}\\n\"\"\"'},\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=100,\n",
        "                top_p=1.0,\n",
        "                frequency_penalty=0.0,\n",
        "                presence_penalty=0.0,\n",
        "            )\n",
        "            if \"choices\" in resp:\n",
        "                return resp['choices'][0]['message']['content']\n",
        "            else:\n",
        "                raise Exception(f\"Invalid API response: {resp}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Error] {e}\")\n",
        "            return None\n",
        "\n",
        "    for entry in entries:\n",
        "        trans = await get(item[entry])\n",
        "        if trans is None:\n",
        "            return None\n",
        "        else:\n",
        "            item[f\"{entry}_zh\"] = trans\n",
        "    return item\n",
        "\n",
        "\n",
        "async def process(id, item, semaphore):\n",
        "    async with semaphore:\n",
        "        file_name = f\"{temp_path}/{output_prefix}_{id}.json\"\n",
        "        try:\n",
        "            it = await getTranslation(item, entries)\n",
        "            if it is None:\n",
        "                raise Exception(file_name)\n",
        "            async with aiofiles.open(file_name, \"w\") as f:\n",
        "                await f.write(json.dumps(it, ensure_ascii=False, indent=4))\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving item: {e}\")\n",
        "\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "      with open(input_file, \"r\") as file:\n",
        "          data = json.load(file)\n",
        "    except json.JSONDecodeError:\n",
        "      data = []\n",
        "      with open(input_file, \"r\") as file:\n",
        "          for line in file:\n",
        "              entry = json.loads(line)\n",
        "              data.append(entry)\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    for id, item in enumerate(data):\n",
        "        if os.path.exists(f\"{output_prefix}{id}.json\"):\n",
        "            continue\n",
        "        tasks.append(asyncio.create_task(process(id, item, semaphore)))\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dqtYwMhZeUVy"
      },
      "source": [
        "由于网络问题或OpenAI的限制会导致获取数据失败，此时脚本会跳过这部分数据\n",
        "\n",
        "重新运行下面的单元格即可补充获取失败的数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVD4JCQULHRF"
      },
      "outputs": [],
      "source": [
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBWIswEldVFt"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for filename in tqdm(os.listdir(temp_path)):\n",
        "    if filename.startswith(output_prefix) and filename.endswith(\".json\"):\n",
        "        with open(os.path.join(temp_path, filename), 'r', encoding='utf-8') as file:\n",
        "            try:\n",
        "                entry = json.load(file)\n",
        "                data.append(entry)\n",
        "            except json.JSONDecodeError:\n",
        "                pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV_z30iOdVFt"
      },
      "outputs": [],
      "source": [
        "file_counter = 1\n",
        "current_file_size = 0\n",
        "output_file = f\"{output_path}/{output_prefix}_{file_counter}.jsonl\"\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as out:\n",
        "    for item in tqdm(data):\n",
        "        item_json = json.dumps(item, ensure_ascii=False)\n",
        "        item_size = len(item_json.encode('utf-8'))\n",
        "        out.write(item_json + \"\\n\")\n",
        "        current_file_size += item_size\n",
        "        if current_file_size > max_file_size:\n",
        "            file_counter += 1\n",
        "            output_file = f\"{output_path}/{output_prefix}_{file_counter}.jsonl\"\n",
        "            out = open(output_file, 'w', encoding='utf-8')\n",
        "            current_file_size = 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
